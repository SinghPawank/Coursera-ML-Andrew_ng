{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your own dataset\n",
    "\n",
    "In this exercise, we provided a preprocessed training set and test set. These datasets were created using the same functions (`processEmail` and `emailFeatures`) that you now have completed. For this optional (ungraded) exercise, you will build your own dataset using the original emails from the SpamAssassin Public Corpus.\n",
    "\n",
    "Your task in this optional (ungraded) exercise is to download the original\n",
    "files from the public corpus and extract them. After extracting them, you should run the `processEmail` and `emailFeatures` functions on each email to extract a feature vector from each email. This will allow you to build a dataset `X`, `y` of examples. You should then randomly divide up the dataset into a training set, a cross validation set and a test set.\n",
    "\n",
    "While you are building your own dataset, we also encourage you to try building your own vocabulary list (by selecting the high frequency words that occur in the dataset) and adding any additional features that you think\n",
    "might be useful. Finally, we also suggest trying to use highly optimized SVM toolboxes such as [`LIBSVM`](https://www.csie.ntu.edu.tw/~cjlin/libsvm/) or [`scikit-learn`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "# Import regular expressions to process emails\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# Optimize with Sklearn svm \n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils\n",
    "\n",
    "%matplotlib inline\n",
    "# for expliting file name with its extention\n",
    "from pathlib import Path\n",
    "# for extracting files\n",
    "import tarfile\n",
    "# for reloading module\n",
    "import importlib\n",
    "# Compute execution time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change directory\n",
    "os.chdir('F:\\Machine_Learning\\ML_by_Andrew_Ng\\Assignments_in_python\\Ex6_week7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing methods\n",
    "import methods\n",
    "importlib.reload(methods)\n",
    "from methods import processEmail,emailFeatures, dataset3Params, gaussian_Kernel, gaussianKernelGramMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files\n",
    "archives_path = 'D:/Mail Sample/Obsolete'# directory of zipped folders\n",
    "extract_path = 'Extracted_files' # directory of unzipped folders\n",
    "for filename in os.listdir(archives_path):\n",
    "    archives = tarfile.open(os.path.join(archives_path, filename)) \n",
    "    archives.extractall(path = extract_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files and writing files to txt\n",
    "path = 'Extracted_files' # directory of unzipped folders\n",
    "pathw = 'Database_' # directory for saving folders of txt files\n",
    "for foldername in os.listdir():\n",
    "    folderpath = os.path.join(pathw, foldername)\n",
    "    os.makedirs(folderpath)\n",
    "    for filename in os.listdir(os.path.join(path, foldername)):       \n",
    "        with open(os.path.join(os.path.join(path, foldername), filename), encoding=\"latin-1\") as f:\n",
    "            file_content = f.read()\n",
    "            filename = Path(filename).stem\n",
    "            with open(os.path.join(folderpath, filename +'.txt'), 'w') as writefile:\n",
    "                writefile.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing and featuring mails, and saving the features in numpy array locally\n",
    "for foldername in os.listdir('Database_'):\n",
    "    X = []\n",
    "    for filename in os.listdir(os.path.join('Database_', foldername)):\n",
    "        with open(os.path.join(os.path.join('Database_', foldername), filename)) as fid:\n",
    "             file_contents = fid.read()\n",
    "        word_indices  = processEmail(file_contents)\n",
    "        X.append(emailFeatures(word_indices))\n",
    "    X_ham = np.array(X)\n",
    "    np.save(os.path.join('Database', foldername + '.npy'), X_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading features \n",
    "X_h1 = np.load('Database/easy_ham.npy')\n",
    "X_h2 = np.load('Database/easy_ham_2.npy')\n",
    "X_h3 = np.load('Database/hard_ham.npy')\n",
    "X_s1 = np.load('Database/spam.npy')\n",
    "X_s2 = np.load('Database/spam_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making single vector for all feature vectors\n",
    "X_h = np.concatenate((X_h1, X_h2, X_h3), axis = 0)\n",
    "X_s = np.concatenate((X_s1, X_s2), axis = 0)\n",
    "X_h_y = np.concatenate((X_h, np.zeros((X_h.shape[0], 1))), axis = 1)\n",
    "X_s_y = np.concatenate((X_s, np.ones((X_s.shape[0],1))), axis = 1)\n",
    "data = np.concatenate((X_h_y, X_s_y), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('Database', 'data.npy'), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('Database/data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    np.random.shuffle(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100, 1899]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the data for train(60%), cross validation(20%) and test(20%)\n",
    "data_train = data[:5600, :]\n",
    "data_val = data[5600:7450, :]\n",
    "data_test = data[7400:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_train[:,:1899].astype(float), data_train[:, -1]\n",
    "X_val, y_val = data_val[:,:1899].astype(float), data_val[:, -1]\n",
    "X_test, y_test = data_test[:,:1899].astype(float), data_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM (Spam Classification)\n",
      "This may take 1 to 2 minutes ...\n",
      "\n",
      "---11 minute(s) 42.99 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "702.9907653331757"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "startTime = time.time()\n",
    "\n",
    "print('Training Linear SVM (Spam Classification)')\n",
    "print('This may take 1 to 2 minutes ...\\n')\n",
    "\n",
    "C = 0.1\n",
    "model = utils.svmTrain(X_train, y_train, C, utils.linearKernel)\n",
    "executionTime(startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "# Compute the training accuracy\n",
    "p = utils.svmPredict(model, X_train)\n",
    "\n",
    "print('Training Accuracy: %.2f' % (np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different SVM Parameters here\n",
    "\n",
    "#C, sigma = dataset3Params(X_train, y_train, X_val, y_val)\n",
    "#print('C = ', C, 'sigma = ', sigma)3\n",
    "# Train the SVM\n",
    "# model = utils.svmTrain(X, y, C, lambda x1, x2: gaussianKernel(x1, x2, sigma))\n",
    "\n",
    "#model = utils.svmTrain(X_train, y_train, C, gaussianKernel, args=(sigma,))\n",
    "\n",
    "# Gaussian Kernal Taking hours to train the model that's why i replaced gaussian kernel whith linear Kernal\n",
    "#model = utils.svmTrain(X_train, y_train, C, utils.linearKernal)\n",
    "# compute the cross-validation accuracy\n",
    "#p = utils.svmPredict(model, X_train)\n",
    "\n",
    "#print('cross-validation Accuracy: %.2f' % (np.mean(p == y_val) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the test accuracy\n",
    "\n",
    "print('Evaluating the trained Linear SVM on a test set ...')\n",
    "p = utils.svmPredict(model, X_test)\n",
    "\n",
    "print('Test Accuracy: %.2f' % (np.mean(p == y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Even we are using linear kernal of utils, it takes more than 10 minuthes to train model with the dataset. It will take hours to train model by utlis.svmTrain with gaussian kernal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model of skikit-learn library\n",
    "### SVM with linear kernal \n",
    "**svm with linear kernal of skikit-learn library is very efficient. It also takes few sec to train model and accurracy is more than 99%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.33 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Training model \n",
    "startTime = time.time()\n",
    "\n",
    "C = 0.1\n",
    "clf = svm.SVC(C = C, kernel = 'linear')\n",
    "\n",
    "model = clf.fit(X_train,y_train)\n",
    "executionTime(startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "# compute the train accuracy\n",
    "\n",
    "p = model.predict(X_train)\n",
    "\n",
    "print('Training Accuracy: %.2f' % (np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4152\n",
      "         1.0       1.00      1.00      1.00      1448\n",
      "\n",
      "    accuracy                           1.00      5600\n",
      "   macro avg       1.00      1.00      1.00      5600\n",
      "weighted avg       1.00      1.00      1.00      5600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy: 99.41\n"
     ]
    }
   ],
   "source": [
    "# compute the cross-validation accuracy\n",
    "\n",
    "p = model.predict(X_val)\n",
    "\n",
    "print('Cross-validation Accuracy: %.2f' % (np.mean(p == y_val) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1407\n",
      "         1.0       0.99      0.99      0.99       443\n",
      "\n",
      "    accuracy                           0.99      1850\n",
      "   macro avg       0.99      0.99      0.99      1850\n",
      "weighted avg       0.99      0.99      0.99      1850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.33\n"
     ]
    }
   ],
   "source": [
    "# compute the test accuracy\n",
    "\n",
    "p = model.predict(X_test)\n",
    "\n",
    "print('Test Accuracy: %.2f' % (np.mean(p == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1427\n",
      "         1.0       0.99      0.99      0.99       526\n",
      "\n",
      "    accuracy                           0.99      1953\n",
      "   macro avg       0.99      0.99      0.99      1953\n",
      "weighted avg       0.99      0.99      0.99      1953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with gaussian kernel of sklearn  \n",
    "**Even SVM with gaussian kernel of skikit-learn library is not efficient with this dataset. It takes minutes to train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  8 minute(s) 3.24 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "startTime = time.time()\n",
    "C = 0.1\n",
    "clf = svm.SVC(C = C, kernel = \"precomputed\")\n",
    "model = clf.fit(gaussianKernelGramMatrix(X_train, X_train), y_train)\n",
    "\n",
    "execTime = time.time() - startTime\n",
    "print(\"--- %2d minute(s) %2.2f seconds ---\" % (execTime//60, execTime%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 74.14\n",
      "---  8 minute(s) 16.20 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "startTime = time.time()\n",
    "p = model.predict(gaussianKernelGramMatrix(X_train, X_train))\n",
    "\n",
    "print('Training Accuracy: %.2f' % (np.mean(p == y_train) * 100))\n",
    "\n",
    "execTime = time.time() - startTime\n",
    "print(\"--- %2d minute(s) %2.2f seconds ---\" % (execTime//60, execTime%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm_GK = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      1.00      0.85      4152\n",
      "         1.0       0.00      0.00      0.00      1448\n",
      "\n",
      "    accuracy                           0.74      5600\n",
      "   macro avg       0.37      0.50      0.43      5600\n",
      "weighted avg       0.55      0.74      0.63      5600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the svm model, predicting with the trained model also takes much time and training accuracy is also very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm import *\n",
    "from libsvm.svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-f5545e5c1d75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[1;31m## training  the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_libsvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#testing the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel_libsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "prob = svm_problem([1,-1],[[1,0,1],[-1,0,-1]])\n",
    "param = svm_parameter('-q')\n",
    "  ## training  the model\n",
    "model_libsvm = svm_model(prob, param)\n",
    "#testing the model\n",
    "model_libsvm.predict([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.857142857142858"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)/len(y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.68159948679568"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data[:,-1])/len(data[:,-1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "libsvm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
